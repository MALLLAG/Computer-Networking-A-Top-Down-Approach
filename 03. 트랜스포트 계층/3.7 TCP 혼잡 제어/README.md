# 3.7 TCP 혼잡 제어 (TCP Congestion Control)

이 절에서는 TCP의 혼잡 제어 메커니즘을 자세히 살펴봅니다.  
앞서 3.5절에서 배운 것처럼, TCP는 신뢰성 있는 데이터 전송 서비스를 제공합니다.  
하지만 또 하나의 중요한 역할은 **혼잡 제어(Congestion Control)** 입니다.

“클래식 TCP(Classic TCP)”라 불리는 표준 TCP(RFC 2581, RFC 5681)는  
**종단 간 혼잡 제어(end-to-end congestion control)** 를 사용합니다.  
즉, IP 계층으로부터 명시적인 피드백을 받지 않고,  
패킷 손실과 지연을 관찰하여 혼잡을 감지합니다.

이 절에서는  
1. 기존 “클래식 TCP” 혼잡 제어  
2. 이후 발전된 TCP 변형(TCP Reno, TCP Cubic 등)  
3. 여러 전송 흐름 간의 공정성 문제  
를 순서대로 다룹니다.

## 3.7.1 클래식 TCP 혼잡 제어 (Classic TCP Congestion Control)

TCP는 각 송신자가 자신의 연결 경로의 혼잡 정도를 **관찰하여 송신 속도를 조절**합니다.
- 혼잡이 적다고 판단되면 송신 속도를 높입니다.
- 혼잡이 많다고 판단되면 송신 속도를 낮춥니다.

이 과정에는 세 가지 중요한 질문이 있습니다:
1. TCP는 송신 속도를 어떻게 제한할까?
2. TCP는 어떻게 혼잡 여부를 인식할까?
3. TCP는 혼잡 수준에 따라 어떤 알고리즘으로 송신 속도를 바꿀까?

### 1. 송신 속도 제한 – 혼잡 윈도우 (Congestion Window)

TCP는 `cwnd`(congestion window)라는 변수를 사용해 송신 속도를 제한합니다.  
`cwnd`는 송신자가 네트워크에 보낼 수 있는 **미확인(ack되지 않은)** 데이터의 최대 양을 의미합니다.

**LastByteSent - LastByteAcked ≤ min(cwnd, rwnd)**


여기서 `rwnd`는 수신 윈도우(Receive Window)입니다.  
혼잡 제어를 설명하기 위해 `rwnd`가 충분히 크다고 가정하면,  
송신 속도는 `cwnd` 값에 의해서만 결정됩니다.

따라서 TCP의 송신 속도는 대략적으로:

> **송신 속도 ≈ cwnd / RTT (bytes/sec)**

입니다.  
즉, `cwnd` 값을 조정함으로써 송신 속도를 제어할 수 있습니다.

### 2. 혼잡 감지 (Congestion Detection)

TCP는 **손실 이벤트(loss event)** 를 통해 혼잡을 감지합니다.  
이는 다음 중 하나로 정의됩니다:
- **타임아웃(timeout)** 발생
- **3중 중복 ACK(three duplicate ACKs)** 수신

라우터 버퍼가 넘쳐 패킷이 손실되면, 송신자는 이를 혼잡 신호로 받아들입니다.  
반대로 ACK이 정상적으로 도착하면, TCP는 네트워크 상태가 양호하다고 판단하고 `cwnd`를 증가시킵니다.

ACK의 도착 속도는 TCP 송신 속도 증가의 ‘시계(clock)’ 역할을 하므로,  
이 메커니즘을 **자기 시계(self-clocking)** 라고 부릅니다.

### 3. 송신 속도 조절 원칙

TCP 송신자는 다음 세 가지 원칙에 따라 송신 속도를 조절합니다:

- **손실된 세그먼트 = 혼잡 발생 → 송신 속도 감소**  
  손실 이벤트(타임아웃 또는 3중 중복 ACK)가 발생하면 `cwnd`를 줄입니다.

- **ACK 수신 = 네트워크 양호 → 송신 속도 증가**  
  ACK이 도착하면 `cwnd`를 늘려 더 많은 데이터를 전송합니다.

- **대역폭 탐색 (Bandwidth Probing)**  
  TCP는 ACK이 도착하는 동안 송신률을 점진적으로 높이다가 손실이 발생하면 다시 줄이는 방식으로  
  이용 가능한 대역폭을 “탐색”합니다.  
  (아이에게 간식을 더 달라고 계속 요청하다가 “그만!” 할 때 멈추는 것과 비슷한 개념입니다.)

## TCP 혼잡 제어 알고리즘

TCP 혼잡 제어는 세 가지 주요 구성요소로 이루어져 있습니다:
1. **Slow Start (느린 시작)**
2. **Congestion Avoidance (혼잡 회피)**
3. **Fast Recovery (빠른 복구)**

### 1. Slow Start (느린 시작)

TCP 연결이 시작될 때, `cwnd`는 보통 1 MSS로 초기화됩니다.  
MSS가 500바이트이고 RTT가 200ms라면 초기 속도는 약 20kbps에 불과합니다.  
이후 매 RTT마다 `cwnd`가 2배씩 증가합니다.

예:
- 1 MSS → 2 MSS → 4 MSS → 8 MSS …

즉, 전송 속도는 **지수적으로 증가**합니다.

그러나 손실이 감지되면,
- `cwnd`는 1 MSS로 리셋되고
- `ssthresh`(slow start threshold)는 `(기존 cwnd) / 2` 로 설정됩니다.

이후 TCP는 **혼잡 회피 모드(Congestion Avoidance)** 로 전환됩니다.

### 2. Congestion Avoidance (혼잡 회피)

이 단계에서는 보다 **보수적으로 송신 속도를 증가**시킵니다.  
매 RTT마다 `cwnd`를 1 MSS씩만 증가시킵니다.  
즉, **선형적 증가(linear increase)** 입니다.

- 손실 이벤트 발생 시:
    - `cwnd = 1 MSS`
    - `ssthresh = cwnd / 2`

- 3중 중복 ACK 발생 시:
    - `cwnd`를 절반으로 줄이고 (여기에 3 MSS 더함),
    - `ssthresh`는 동일하게 `(기존 cwnd) / 2` 로 설정
    - 그 후 **Fast Recovery** 단계로 진입

### 3. Fast Recovery (빠른 복구)

Fast Recovery는 선택적 기능이지만, 대부분의 TCP 구현에서 사용됩니다.  
이 방식은 **타임아웃으로 인한 재전송보다 빠르게 회복**합니다.

- 3중 중복 ACK을 받으면 손실 세그먼트를 재전송하고 `cwnd`를 조정합니다.
- ACK이 누락된 세그먼트를 성공적으로 확인하면 TCP는 정상 전송으로 복귀합니다.

TCP Tahoe는 Fast Recovery를 사용하지 않았지만,  
TCP Reno는 이를 포함하여 성능을 향상시켰습니다.

## TCP Reno vs TCP Cubic

TCP Reno는 **AIMD(Additive Increase, Multiplicative Decrease)** 방식을 사용합니다.
- ACK마다 선형 증가(additive increase)
- 손실 이벤트마다 절반 감소(multiplicative decrease)

그래서 **톱니 모양(sawtooth)** 형태의 전송률 변화가 나타납니다.

TCP Cubic은 이를 개선한 버전으로,  
**혼잡 회피 구간을 큐빅 함수(cubic function)** 로 조정합니다.

- 손실 후 빠르게 회복
- 혼잡 임계치에 가까워질수록 신중하게 증가

즉, Cubic은 **혼잡 임계점 근처에서 안정적이면서도 빠른 회복**을 목표로 합니다.  
현재 리눅스의 기본 TCP 버전이며, 웹 서버의 절반 이상이 TCP Cubic을 사용합니다.

| 단계 | 동작 방식 | 윈도우 변화 |
|------|------------|-------------|
| Slow Start | 송신 속도 지수적 증가 | 1 MSS → 2 → 4 → 8 … |
| Congestion Avoidance | 선형 증가 | +1 MSS/RTT |
| Fast Recovery | 손실 후 빠른 회복 | 절반 감소 후 점진적 복구 |
| TCP Reno | AIMD (Additive Increase, Multiplicative Decrease) | 톱니형 변화 |
| TCP Cubic | 큐빅 함수 기반 혼잡 회피 | 더 빠르고 안정적인 회복 |


## 3.7.2 네트워크 지원 명시적 혼잡 알림(ECN)과 지연 기반 혼잡 제어

TCP는 1980년대 후반부터 슬로우 스타트(slow start)와 혼잡 회피(congestion avoidance)를 도입했습니다.  
그 이후 TCP는 **종단 간 혼잡 제어(end-to-end congestion control)** 방식을 유지해왔습니다.  
즉, 네트워크 계층으로부터 명시적인 혼잡 알림을 받지 않고, 패킷 손실을 관찰하여 혼잡을 추정합니다.

하지만 이후 **IP와 TCP의 확장 기능(RFC 3168)** 이 추가되어,  
네트워크가 송신자에게 직접 혼잡 상태를 **명시적으로 알릴 수 있는 방법(Explicit Congestion Notification, ECN)** 이 도입되었습니다.  
또한, 일부 TCP 변형은 패킷 손실이 발생하기 전에 **RTT 지연(Delay)을 기반으로 혼잡을 예측**하는 방식도 제안되었습니다.

이 절에서는 **명시적 혼잡 알림(ECN)** 과 **지연 기반 혼잡 제어(Delay-based Control)** 두 가지를 다룹니다.

### 명시적 혼잡 알림 (Explicit Congestion Notification, ECN)

ECN은 RFC 3168에서 정의된 **네트워크 지원형 혼잡 제어 메커니즘**입니다.  
IP 계층과 TCP 계층이 모두 관여합니다.

- IP 헤더의 Type of Service(TOS) 필드 안에는 2개의 ECN 비트가 존재하며,  
  라우터가 혼잡 상태를 탐지했을 때 이 비트를 설정하여 송신자에게 알립니다.
- ECN은 패킷 손실이 발생하기 전에 혼잡 신호를 보내는 것이 핵심입니다.

**작동 과정 요약:**
1. 라우터가 혼잡을 감지하면 IP 데이터그램의 ECN 비트를 설정(표시)합니다.
2. 목적지 호스트(TCP 수신자)는 이를 확인한 후, 송신자에게 ACK 패킷 내의 **ECE (Explicit Congestion Notification Echo)** 비트를 설정하여 알립니다.
3. 송신자는 이를 수신하면 `cwnd`(혼잡 윈도우)를 절반으로 줄이고,  
   다음 송신 패킷의 헤더에 **CWR (Congestion Window Reduced)** 비트를 설정해 응답합니다.

즉, ECN은 **패킷 손실 없이 혼잡 신호를 주고받을 수 있는 구조**를 제공합니다.

**참고:**  
TCP 외에도 ECN을 사용하는 다양한 프로토콜이 존재합니다.
- **DCCP (Datagram Congestion Control Protocol)** — UDP 기반의 혼잡 제어 프로토콜
- **DCTCP (Data Center TCP)** — 데이터센터용 TCP로, ECN을 활용하여 세밀한 혼잡 조절 수행
- **DCQCN (Data Center Quantized Congestion Notification)** — 데이터센터 전용 혼잡 제어 방식으로, ECN 기반 신호를 사용

최근 인터넷 환경에서는 주요 서버와 라우터들이 ECN을 지원하는 경우가 점점 증가하고 있습니다.

### 지연 기반 혼잡 제어 (Delay-based Congestion Control)

ECN이 **혼잡 발생 직전**에 송신자에게 신호를 주는 방식이라면,  
지연 기반 혼잡 제어는 **지연 시간(RTT)을 측정하여 혼잡을 미리 예측**합니다.

즉, 패킷 손실이 발생하기 전에 RTT가 증가하는 것을 감지하고,  
그에 따라 송신 속도를 줄여 혼잡을 방지합니다.

#### TCP Vegas (Brakmo, 1995)

TCP Vegas는 RTT(왕복 지연 시간)를 측정하여 혼잡을 예측하는 대표적인 지연 기반 프로토콜입니다.

- 송신자는 각 ACK 패킷에 대해 RTT를 측정합니다.
- RTT 중 최소값(`RTT_min`)은 네트워크가 비혼잡 상태일 때의 지연입니다.
- 이때의 이상적 처리율은 `cwnd / RTT_min` 입니다.
- 실제 측정된 처리율이 이 값보다 **낮다면 혼잡이 발생하고 있는 것**으로 판단합니다.  
  → 송신 속도를 줄입니다.
- 반대로 실제 처리율이 근접하거나 더 높다면,  
  → 네트워크가 원활하다고 판단하여 송신 속도를 늘립니다.

즉, **혼잡을 미리 감지하고 예방적으로 송신률을 조정하는 방식**입니다.

#### Vegas의 직관적 원리

TCP Vegas의 기본 아이디어는 다음 문장으로 요약됩니다:

> “Keep the pipe just full, but no fuller.”  
> (파이프를 가득 채우되, 넘치게 하지 말라.)

즉, 병목 구간의 링크를 **항상 가득 채워 효율을 극대화**하되,  
버퍼가 넘쳐 지연이 급증하지 않도록 **미세 조정**하는 접근 방식입니다.  
이 방식은 단순한 손실 감지 기반보다 훨씬 부드럽고 효율적인 트래픽 제어를 가능하게 합니다.

### BBR (Bottleneck Bandwidth and RTT)

**BBR 혼잡 제어 알고리즘**(Cardwell, 2017)은 TCP Vegas의 아이디어를 확장한 방식입니다.
- BBR은 **대역폭(Bandwidth)** 과 **RTT** 를 동시에 측정하여  
  네트워크의 실제 용량을 모델링하고 최적 송신 속도를 계산합니다.
- Google은 2016년부터 **자체 네트워크(B4)** 와 YouTube 서버에 BBR을 도입했습니다.  
  이는 기존 Cubic을 대체하고 있습니다.

BBR은 지연 기반 TCP 알고리즘들(TCP Vegas, FAST, CTCP 등)과 유사하게  
“혼잡을 미리 감지하고 능동적으로 제어”하는 방식을 따릅니다.

이 절에서는 TCP가 혼잡을 탐지하는 두 가지 고급 방법을 살펴보았습니다.
1. **ECN:** 네트워크가 송신자에게 혼잡 상태를 명시적으로 알리는 방식
2. **지연 기반 제어:** RTT 변화를 이용해 혼잡을 미리 감지하는 방식

이 두 접근법은 TCP 성능 향상과 네트워크 효율성 확보에 핵심적인 역할을 합니다.





## 3.7.3 공정성 (Fairness)

TCP의 혼잡 제어는 네트워크의 링크 대역폭을 여러 연결이 **공정하게(fair)** 나누어 사용하는 것을 목표로 합니다.

### 기본 개념

`K`개의 TCP 연결이 있다고 가정합니다.  
각 연결은 서로 다른 경로를 통해 통신하지만, 모두 **하나의 병목 링크(bottleneck link)** 를 공유합니다.  
이 링크의 전송 속도를 `R bps`라고 하면, 각 TCP 연결이 얻는 평균 전송률이 약 `R/K`라면 그 혼잡 제어 메커니즘은 **공정하다(fair)** 고 합니다.

즉, **모든 연결이 링크 용량을 균등하게 나누어 가지는 상태**를 이상적인 공정성으로 정의합니다.

### TCP의 AIMD 알고리즘은 공정한가?

TCP는 혼잡 제어 시 **AIMD(Additive Increase, Multiplicative Decrease)** 알고리즘을 사용합니다.  
이 알고리즘이 실제로 공정한 결과를 내는지 살펴보겠습니다.

다음은 단순화를 위한 가정입니다:
- 두 개의 TCP 연결이 동일한 병목 링크(`R bps`)를 공유합니다.
- 두 연결의 **MSS**와 **RTT**는 같습니다.
- 두 연결은 항상 충분한 데이터를 전송할 수 있습니다.
- TCP는 **혼잡 회피(CA)** 단계(AIMD 모드)에 있습니다.

이때 이상적인 상황에서는 두 연결의 처리량이 45도 대각선(즉, `throughput1 + throughput2 = R`) 근처에 위치해야 합니다.  
즉, 두 연결이 **동일한 비율로 링크 대역폭을 공유**하는 상태입니다.

### AIMD의 공정성 수렴 원리

1. 처음에 두 연결의 윈도우 크기가 작다고 가정합니다 (점 A).  
   → 총 대역폭 사용량이 `R`보다 작기 때문에 손실이 없습니다.  
   → 두 연결은 각 RTT마다 윈도우를 +1 MSS씩 증가시킵니다.  
   → 두 처리량은 함께 45도 선을 따라 증가합니다.

2. 어느 시점에서 합쳐진 대역폭이 `R`을 초과하면 손실이 발생합니다 (점 B).  
   → 두 연결은 각각 윈도우를 절반으로 줄입니다 (점 C).

3. 그 후 다시 윈도우를 늘리고, 또 손실이 발생하면 절반으로 줄이는 과정을 반복합니다 (점 D…).  
   → 이 과정을 계속 반복하면 **평균적으로 두 연결의 대역폭이 동일해지는 선(공정선)** 근처에 수렴합니다.

즉, AIMD는 시간 경과에 따라 **공정한 대역폭 분배로 수렴**합니다.  
이는 TCP가 여러 연결 사이에서 자원을 균등하게 나누는 이유를 직관적으로 설명해 줍니다.

### RTT의 영향

실제 네트워크에서는 각 연결의 RTT가 다릅니다.  
RTT가 작은 연결은 더 빠르게 ACK을 받기 때문에 **혼잡 윈도우를 더 자주 증가시킬 수 있습니다.**  
결과적으로, **RTT가 짧은 연결은 RTT가 긴 연결보다 더 많은 대역폭을 차지하게 됩니다.**  
→ 이것이 TCP 공정성의 현실적인 한계 중 하나입니다.

## Fairness and UDP (UDP와의 공정성 문제)

TCP는 혼잡 제어를 통해 네트워크가 혼잡해지면 송신 속도를 줄입니다.  
하지만 **UDP는 혼잡 제어 기능이 없습니다.**

인터넷 전화(VoIP), 화상회의 같은 실시간 멀티미디어 애플리케이션은  
전송률이 줄어드는 것을 원하지 않기 때문에 TCP 대신 UDP를 사용합니다.

- UDP는 혼잡 시에도 전송률을 유지하려고 합니다.
- 대신 패킷 손실이 발생하면 품질이 저하되지만 전송 속도는 일정합니다.

이 때문에 UDP는 TCP에 비해 **비공정한(fair하지 않은)** 행동을 하게 됩니다.  
TCP 연결이 손실로 인해 속도를 줄이는 동안, UDP는 속도를 유지하므로  
**UDP 트래픽이 TCP 트래픽을 밀어내는(crowd out)** 상황이 발생할 수 있습니다.

이를 해결하기 위해 **UDP용 혼잡 제어 메커니즘**이 제안되었으며,  
RFC 4340(DCCP) 등이 대표적인 예입니다.  
이러한 메커니즘은 UDP 트래픽이 네트워크 전체 처리량을 저하시키지 않도록 방지합니다.

## Fairness and Parallel TCP Connections (병렬 TCP 연결과 공정성)

UDP가 아니더라도 공정성 문제는 완전히 사라지지 않습니다.  
이유는 **TCP 기반 애플리케이션이 여러 개의 병렬 연결을 사용할 수 있기 때문**입니다.

예를 들어:
- 웹 브라우저는 한 페이지 내 여러 객체(이미지, 스크립트 등)를 전송하기 위해  
  **다수의 병렬 TCP 연결**을 엽니다.
- 이렇게 하면 각 연결이 병목 링크 대역폭을 나누어 가지므로,  
  하나의 TCP 연결만 사용하는 애플리케이션보다 **더 많은 대역폭을 차지**하게 됩니다.

예시:
- 병목 링크 용량: `R`
- 9개의 기존 애플리케이션이 각각 1개의 TCP 연결 사용 → 각자 `R/10` 획득
- 새로운 애플리케이션이 **11개의 병렬 TCP 연결**을 사용하면  
  → `11 × (R/10)` ≈ `R/2` 이상의 대역폭을 차지하게 됨  
  → 결과적으로 **불공정한 대역폭 분배** 발생

이처럼 웹 트래픽은 다중 TCP 연결을 자주 사용하기 때문에  
실제 인터넷에서는 완전한 공정성을 보장하기 어렵습니다.

요약하면, AIMD 알고리즘은 본질적으로 공정성을 향해 수렴하지만,  
현실 세계에서는 **RTT 차이, UDP 트래픽, 병렬 연결** 등으로 인해 완전한 공정성은 달성되지 않습니다.





